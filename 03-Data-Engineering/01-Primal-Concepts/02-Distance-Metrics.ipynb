{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4b16f5d",
   "metadata": {},
   "source": [
    "# Distance Metrics\n",
    "\n",
    "Distance metrics are used to quantify the similarity or dissimilarity between data points. Here are some commonly used distance metrics in machine learning:\n",
    "\n",
    "- Euclidean distance\n",
    "- Manhattan distance\n",
    "- Minkowski distance\n",
    "- Cosine distance\n",
    "- Hamming distance\n",
    "- Jaccard distance\n",
    "\n",
    "## Euclidean Distance\n",
    "\n",
    "Euclidean distance is a measure of the distance between two points in a two- or multi-dimensional space. It is based on the Pythagorean theorem, which states that the square of the hypotenuse of a right triangle is equal to the sum of the squares of the other two sides. The Euclidean distance between two points can be calculated by finding the square root of the sum of the squares of the differences between the corresponding coordinates.\n",
    "\n",
    "For example, let's consider two points in a two-dimensional space: `(x1, y1)` and `(x2, y2)`. The Euclidean distance between these two points can be calculated as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "distance = \\sqrt{(x2 - x1)^2 + (y2 - y1)^2}\n",
    "\\end{equation}\n",
    "\n",
    "In a multi-dimensional space, the formula is similar, but includes the differences between all corresponding coordinates:\n",
    "\n",
    "\\begin{equation}\n",
    "distance = \\sqrt{(x2 - x1)^2 + (y2 - y1)^2 + ... + (zn - zm)^2}\n",
    "\\end{equation}\n",
    "\n",
    "In general, we can calculate eucledian distance as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "d_{\\text{euclidean}}(\\mathbf{p}, \\mathbf{q}) = \\sqrt{\\sum_{i=1}^{n}(q_i - p_i)^2}\n",
    "\\end{equation}\n",
    "\n",
    "To implement Euclidean distance in Python, you can define a function that takes two points as input and returns the distance between them. Here's an example implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0c8d86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"Calculates the Euclidean distance between two points.\"\"\"\n",
    "    squared_distance = 0\n",
    "    for i in range(len(point1)):\n",
    "        squared_distance += (point1[i] - point2[i])**2\n",
    "    distance = math.sqrt(squared_distance)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2947f4",
   "metadata": {},
   "source": [
    "The function takes two arguments, `point1` and `point2`, which are lists or tuples of the same length containing the coordinates of the two points. The function first initializes a variable `squared_distance` to 0, then iterates over the coordinates of the points and adds the squared differences to `squared_distance`. Finally, it takes the square root of `squared_distance` and returns the resulting value as the Euclidean distance between the two points.\n",
    "\n",
    "Here's an example usage of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175d243a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.196152422706632\n"
     ]
    }
   ],
   "source": [
    "point1 = (1, 2, 3)\n",
    "point2 = (4, 5, 6)\n",
    "distance = euclidean_distance(point1, point2)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b0ee43",
   "metadata": {},
   "source": [
    "In this example, we calculate the Euclidean distance between two points in a three-dimensional space. The output is the distance between the two points, which is approximately `5.2`.\n",
    "\n",
    "## Manhattan Distance\n",
    "\n",
    "Manhattan distance is a distance metric used in machine learning to measure the distance between two points in a n-dimensional space. It is also known as taxicab distance or L1 distance. Unlike Euclidean distance, Manhattan distance does not calculate the shortest distance between two points in a straight line. Instead, it calculates the distance between two points by summing up the absolute differences between the corresponding coordinates of the two points.\n",
    "\n",
    "The Manhattan distance between two points $\\mathbf{p}=(p_1, p_2, \\dots, p_n)$ and $\\mathbf{q}=(q_1, q_2, \\dots, q_n)$ in a n-dimensional space is given by the formula:\n",
    "\n",
    "\\begin{equation}\n",
    "d_{\\text{manhattan}}(\\mathbf{p}, \\mathbf{q}) = \\sum_{i=1}^{n}|q_i - p_i|\n",
    "\\end{equation}\n",
    "\n",
    "To implement Manhattan distance in Python, we can define a function that takes two n-dimensional vectors as inputs and calculates the Manhattan distance between them using the above formula. Here's an example implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf86784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(p, q):\n",
    "    \"\"\"\n",
    "    Calculate the Manhattan distance between two vectors p and q.\n",
    "    \n",
    "    Args:\n",
    "    p (list or numpy array): The first vector.\n",
    "    q (list or numpy array): The second vector.\n",
    "    \n",
    "    Returns:\n",
    "    The Manhattan distance between p and q.\n",
    "    \"\"\"\n",
    "    return sum(abs(qi - pi) for pi, qi in zip(p, q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ff5588",
   "metadata": {},
   "source": [
    "In this implementation, we first define a function `manhattan_distance` that takes two vectors `p` and `q` as inputs. We then use the built-in `zip` function to iterate over the corresponding coordinates of `p` and `q`, and calculate the absolute difference between each pair of coordinates. We then sum up these absolute differences to obtain the Manhattan distance between `p` and `q`. Finally, we return the Manhattan distance as the output of the function.\n",
    "\n",
    "Here's an example usage of the manhattan_distance function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dcf8919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Manhattan distance between [1, 2, 3] and [4, 5, 6] is 9\n"
     ]
    }
   ],
   "source": [
    "p = [1, 2, 3]\n",
    "q = [4, 5, 6]\n",
    "d = manhattan_distance(p, q)\n",
    "print(\"The Manhattan distance between\", p, \"and\", q, \"is\", d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3696e28",
   "metadata": {},
   "source": [
    "## Minkowski Distance\n",
    "\n",
    "The Minkowski distance is a generalization of other distance measures such as the Euclidean distance and the Manhattan distance. It is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "D_{p}(X,Y)=\\left(\\sum_{i=1}^{n}|x_i-y_i|^p\\right)^{\\frac{1}{p}}\n",
    "\\end{equation}\n",
    "\n",
    "where $X$ and $Y$ are two vectors of equal dimensionality, $n$, and $p$ is a positive real number. When $p=1$, this is equivalent to the Manhattan distance, and when $p=2$, this is equivalent to the Euclidean distance.\n",
    "\n",
    "Here's an example of calculating the Minkowski distance between two vectors in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5ddb535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def minkowski_distance(x, y, p):\n",
    "    \"\"\"\n",
    "    Calculates the Minkowski distance between two vectors x and y\n",
    "    of equal dimensionality, using the specified value of p.\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    distance = np.sum(np.abs(x - y) ** p) ** (1/p)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43ac1861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3267487109222245\n"
     ]
    }
   ],
   "source": [
    "x = [1, 2, 3]\n",
    "y = [4, 5, 6]\n",
    "p = 3\n",
    "distance = minkowski_distance(x, y, p)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da63b96d",
   "metadata": {},
   "source": [
    "In this example, we define a function `minkowski_distance` that takes two vectors `x` and `y` and a value of `p`, and calculates the Minkowski distance between the two vectors using the above formula. We then use this function to calculate the distance between the two vectors `[1, 2, 3]` and `[4, 5, 6]` with `p=3`, which gives a distance of approximately `5.196`.\n",
    "\n",
    "## Cosine Distance\n",
    "\n",
    "Cosine distance is a distance metric used in machine learning to measure the similarity between two non-zero vectors in a high-dimensional space. It is based on the cosine similarity measure, which calculates the cosine of the angle between two vectors. The cosine distance between two vectors $\\mathbf{p}$ and $\\mathbf{q}$ is defined as 1 minus the cosine similarity between the two vectors:\n",
    "\n",
    "\\begin{equation}\n",
    "d_{\\text{cosine}}(\\mathbf{p}, \\mathbf{q}) = 1 - \\frac{\\mathbf{p} \\cdot \\mathbf{q}}{\\|\\mathbf{p}\\|_2\\|\\mathbf{q}\\|_2}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\cdot$ denotes the dot product of two vectors, and $|\\cdot|_2$ denotes the `L2` norm of a vector.\n",
    "\n",
    "To implement cosine distance in Python, we can define a function that takes two vectors as inputs and calculates the cosine distance between them using the above formula. Here's an example implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44013ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_distance(p, q):\n",
    "    \"\"\"\n",
    "    Calculate the cosine distance between two vectors p and q.\n",
    "    \n",
    "    Args:\n",
    "    p (list or numpy array): The first vector.\n",
    "    q (list or numpy array): The second vector.\n",
    "    \n",
    "    Returns:\n",
    "    The cosine distance between p and q.\n",
    "    \"\"\"\n",
    "    p = np.asarray(p)\n",
    "    q = np.asarray(q)\n",
    "    dot_product = np.dot(p, q)\n",
    "    norm_p = np.linalg.norm(p)\n",
    "    norm_q = np.linalg.norm(q)\n",
    "    cosine_similarity = dot_product / (norm_p * norm_q)\n",
    "    cosine_distance = 1 - cosine_similarity\n",
    "    return cosine_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939250a3",
   "metadata": {},
   "source": [
    "In this implementation, we first convert the input vectors `p` and `q` to NumPy arrays using the `numpy.asarray` function. We then use the built-in `numpy.dot` function to calculate the dot product of `p` and `q`, and use the `numpy.linalg.norm` function to calculate the `L2` norm of `p` and `q`. We then use these values to calculate the cosine similarity between `p` and `q`, and subtract it from `1` to obtain the cosine distance between `p` and `q`. Finally, we return the cosine distance as the output of the function.\n",
    "\n",
    "Here's an example usage of the cosine_distance function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d6dc663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine distance between [1, 2, 3] and [4, 5, 6] is 0.025368153802923787\n"
     ]
    }
   ],
   "source": [
    "p = [1, 2, 3]\n",
    "q = [4, 5, 6]\n",
    "d = cosine_distance(p, q)\n",
    "print(\"The cosine distance between\", p, \"and\", q, \"is\", d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2108fcd1",
   "metadata": {},
   "source": [
    "### While talking about Manhattan and Cosine distances we saw L1 and L2 norms respectively. What are those?\n",
    "\n",
    "L1 and L2 norms are ways to measure the size or magnitude of a vector in a high-dimensional space.\n",
    "\n",
    "The L1 norm, also known as the Manhattan norm or taxicab norm, measures the absolute differences between the elements of a vector. It is calculated as the sum of the absolute values of the vector elements:\n",
    "\n",
    "\\begin{equation}\n",
    "\\|\\mathbf{v}\\|_1 = \\sum_{i=1}^n |v_i|\n",
    "\\end{equation}\n",
    " \n",
    "where $\\mathbf{v}$ is the vector, and $n$ is the number of elements in the vector.\n",
    "\n",
    "The L2 norm, also known as the Euclidean norm, measures the distance between the origin and the point represented by the vector. It is calculated as the square root of the sum of the squared elements of the vector:\n",
    "\n",
    "\\begin{equation}\n",
    "\\|\\mathbf{v}\\|_2 = \\sqrt{\\sum_{i=1}^n v_i^2}\n",
    "\\end{equation}\n",
    " \n",
    "where $\\mathbf{v}$ is the vector, and $n$ is the number of elements in the vector.\n",
    "\n",
    "In machine learning, the L2 norm is often used as a regularization term in the objective function of a learning algorithm, while the L1 norm is used in sparse feature selection, where only a small subset of the features are relevant. The choice between L1 and L2 regularization depends on the specific problem and the desired properties of the learned model.\n",
    "\n",
    "In Python, the L1 and L2 norms can be calculated using the `numpy.linalg.norm` function. Here's an example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "204829ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 norm of [1 2 3] is 6.0\n",
      "L2 norm of [1 2 3] is 3.7416573867739413\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "v = np.array([1, 2, 3])\n",
    "\n",
    "# Calculate L1 norm\n",
    "l1_norm = np.linalg.norm(v, ord=1)\n",
    "print(\"L1 norm of\", v, \"is\", l1_norm)\n",
    "\n",
    "# Calculate L2 norm\n",
    "l2_norm = np.linalg.norm(v, ord=2)\n",
    "print(\"L2 norm of\", v, \"is\", l2_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d8ea6",
   "metadata": {},
   "source": [
    "## Hamming Distance\n",
    "\n",
    "The Hamming distance is a measure of similarity between two strings of equal length, defined as the number of positions at which the corresponding symbols are different. In other words, it is the minimum number of substitutions required to change one string into the other.\n",
    "\n",
    "For example, the Hamming distance between the strings \"10110\" and \"11100\" is 2, because the second and fourth symbols differ between the two strings.\n",
    "\n",
    "The Hamming distance can be calculated using the following formula:\n",
    "\n",
    "\\begin{equation}\n",
    "d_{\\text{hamming}}(\\mathbf{p}, \\mathbf{q}) = \\sum_{i=1}^{n}[p_i \\neq q_i]\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{p}$ and $\\mathbf{q}$ are the two strings of length $n$, and $[p_i \\neq q_i]$ is an indicator function that evaluates to 1 if $p_i \\neq q_i$, and 0 otherwise.\n",
    "\n",
    "In Python, the Hamming distance can be calculated using the hamming function from the `scipy.spatial.distance` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1f4f286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming distance between 10110 and 11100 is 0.4\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import hamming\n",
    "\n",
    "s1 = \"10110\"\n",
    "s2 = \"11100\"\n",
    "\n",
    "hamming_distance = hamming(list(s1), list(s2))\n",
    "print(\"Hamming distance between\", s1, \"and\", s2, \"is\", hamming_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed20670",
   "metadata": {},
   "source": [
    "Note that the `hamming` function expects its input arguments to be sequences (e.g., lists) of individual symbols, rather than strings. Therefore, we convert the input strings to lists of characters using the `list` function before passing them to the `hamming` function. The output value of `0.4` indicates that the Hamming distance between the two strings is `2` (since there are a total of `5` symbols and `2` of them differ between the two strings).\n",
    "\n",
    "## Jaccard Distance\n",
    "\n",
    "The Jaccard distance is a measure of similarity between two sets, defined as the ratio of the size of their intersection to the size of their union. It ranges from 0 (indicating no similarity) to 1 (indicating perfect similarity).\n",
    "\n",
    "Formally, the Jaccard distance between two sets $p$ and $q$ is given by:\n",
    "\n",
    "\\begin{equation}\n",
    "d_{\\text{jaccard}}(\\mathbf{p}, \\mathbf{q}) = 1 - \\frac{\\mathbf{p} \\cap \\mathbf{q}}{\\mathbf{p} \\cup \\mathbf{q}}\n",
    "\\end{equation}\n",
    "\n",
    "where $|p \\cap q|$ represents the size of the intersection of sets $p$ and $q$, and $|p \\cup q|$ represents the size of their union.\n",
    "\n",
    "In Python, the Jaccard distance can be calculated using the jaccard function from the `scipy.spatial.distance` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b2b1e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard distance between [1, 2, 3, 4] and [2, 3, 5, 6] is 1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import jaccard\n",
    "\n",
    "s1 = [1, 2, 3, 4]\n",
    "s2 = [2, 3, 5, 6]\n",
    "\n",
    "jaccard_distance = jaccard(s1, s2)\n",
    "print(\"Jaccard distance between\", s1, \"and\", s2, \"is\", jaccard_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9083b",
   "metadata": {},
   "source": [
    "## How do I choose a perfect distance metric for my problem?\n",
    "\n",
    "The choice of distance metric depends on the type of data you are working with and the problem you are trying to solve. Here are some guidelines:\n",
    "\n",
    "- **Euclidean distance:** This is a good choice when the data is continuous and the dimensions are independent of each other. It is also appropriate when you want to penalize larger differences between values more heavily than smaller differences.\n",
    "\n",
    "- **Manhattan distance:** This is a good choice when the data is continuous and the dimensions are independent of each other, but you want to penalize larger differences less heavily than Euclidean distance.\n",
    "\n",
    "- **Minkowski distance:** This is a generalization of Euclidean and Manhattan distance, and is a good choice when you want to control the degree of emphasis given to larger differences between values. If you use a value of p=1, it is equivalent to Manhattan distance, and if you use a value of p=2, it is equivalent to Euclidean distance.\n",
    "\n",
    "- **Cosine distance:** This is a good choice when you are working with sparse data or text data, and you want to measure the similarity between vectors without being affected by the magnitude of the vectors.\n",
    "\n",
    "- **Hamming distance:** This is a good choice when you are working with binary data or categorical data, and you want to measure the number of positions at which the two vectors differ.\n",
    "\n",
    "- **Jaccard distance:** This is a good choice when you are working with binary or categorical data, and you want to measure the similarity between sets of data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
