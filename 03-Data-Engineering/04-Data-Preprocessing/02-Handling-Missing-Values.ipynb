{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f77770c1",
   "metadata": {},
   "source": [
    "# Handling Missing Values\n",
    "\n",
    "Missing data is a common problem in real-world data analysis. It can arise due to various reasons such as data collection errors, data corruption, data entry errors, or data loss. Incomplete data can have a significant impact on the accuracy and reliability of the analysis results. Therefore, handling missing values is an important aspect of data preprocessing in data science.\n",
    "\n",
    "There are several ways to handle missing data, and the most commonly used methods are as follows:\n",
    "\n",
    "## Deletion\n",
    "\n",
    "Deletion refers to removing the rows or columns that contain missing values from the dataset. This is the simplest approach and is often used when the amount of missing data is small. There are three types of deletion:\n",
    "\n",
    "- **Listwise deletion (or complete case analysis):** This involves removing any row that contains missing values. This can lead to a significant loss of data, especially if the percentage of missing values is high.\n",
    "- **Pairwise deletion:** This involves removing only the missing values in a particular column and keeping the rest of the data. This approach retains more data than listwise deletion but may lead to biased estimates if the missing values are not missing completely at random (MCAR) or missing at random (MAR).\n",
    "- **Column-wise deletion:** It involves removing all the variables that have at least one missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b0e7d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "    col1  col2  col3\n",
      "0   1.0   6.0  11.0\n",
      "1   2.0   NaN  12.0\n",
      "2   NaN   8.0  13.0\n",
      "3   4.0   9.0   NaN\n",
      "4   5.0  10.0  15.0\n",
      "\n",
      "Dataframe after list-wise deletion:\n",
      "    col1  col2  col3\n",
      "0   1.0   6.0  11.0\n",
      "4   5.0  10.0  15.0\n",
      "\n",
      "Dataframe after pair-wise deletion:\n",
      "    col1  col2  col3\n",
      "0   1.0   6.0  11.0\n",
      "3   4.0   9.0   NaN\n",
      "4   5.0  10.0  15.0\n",
      "\n",
      "Dataframe after column-wise deletion:\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create a dataframe with missing values\n",
    "df = pd.DataFrame({\n",
    "    'col1': [1, 2, np.nan, 4, 5],\n",
    "    'col2': [6, np.nan, 8, 9, 10],\n",
    "    'col3': [11, 12, 13, np.nan, 15]\n",
    "})\n",
    "\n",
    "# display the dataframe\n",
    "print(\"Original data:\\n\", df)\n",
    "\n",
    "# List-wise deletion\n",
    "new_df = df.dropna()\n",
    "print(\"\\nDataframe after list-wise deletion:\\n\", new_df)\n",
    "\n",
    "# Pair-wise deletion\n",
    "new_df = df.dropna(subset=['col1', 'col2'])\n",
    "print(\"\\nDataframe after pair-wise deletion:\\n\", new_df)\n",
    "\n",
    "# Column-wise deletion\n",
    "new_df = df.dropna(axis=1)\n",
    "print(\"\\nDataframe after column-wise deletion:\\n\", new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc46f5",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "\n",
    "Imputation involves filling in the missing values with a substitute value. The substitute value can be a fixed value such as the mean or median of the column or a predicted value based on the values of other variables in the dataset. There are several types of imputation methods:\n",
    "\n",
    "- **Mean Imputation:** Mean imputation is a simple technique that involves replacing missing values with the mean value of the non-missing values in the same column. This method is commonly used for continuous variables with a normal distribution. Mean imputation is a quick and easy method, but it can lead to biased estimates and increased variance if the data has outliers or is skewed.\n",
    "- **Median Imputation:** Median imputation is similar to mean imputation, but instead of using the mean, it uses the median value of the non-missing values in the same column to replace missing values. Median imputation is a better option for data with outliers or a skewed distribution. However, like mean imputation, it can also lead to biased estimates and increased variance.\n",
    "- **Mode Imputation:** Mode imputation is used for categorical variables and involves replacing missing values with the mode (most common value) of the non-missing values in the same column. This method is quick and easy, but it can lead to biased estimates if the mode is not representative of the population or if there are multiple modes.\n",
    "- **Regression Imputation:** Regression imputation is a more sophisticated technique that involves predicting the missing values based on the relationship between the missing variable and other variables in the dataset. This method requires the use of a regression model to predict the missing values based on other variables in the dataset. The advantage of this method is that it can lead to more accurate estimates of the missing values, but it requires a strong relationship between the missing variable and the other variables.\n",
    "- **Hot-Deck Imputation:** Hot-deck imputation is a method that involves replacing missing values with values from similar cases in the dataset. This method is similar to regression imputation, but instead of using a regression model, it uses the values from similar cases in the dataset. Hot-deck imputation can be useful when there is a high correlation between the missing variable and other variables in the dataset. However, it can also lead to biased estimates if the selected cases are not representative of the population.\n",
    "- **K-Nearest Neighbors (KNN) imputation:** This involves predicting the missing values using the values of the k-nearest neighbors in the dataset. This can be a more flexible approach than regression imputation as it does not require a linear relationship between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "457fa0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "    col1  col2  col3\n",
      "0   1.0   6.0  11.0\n",
      "1   2.0   NaN  12.0\n",
      "2   NaN   8.0  13.0\n",
      "3   4.0   9.0   NaN\n",
      "4   5.0  10.0  15.0\n",
      "\n",
      "Mean Imputation:\n",
      "    col1  col2  col3\n",
      "0   1.0   6.0  11.0\n",
      "1   2.0   NaN  12.0\n",
      "2   3.0   8.0  13.0\n",
      "3   4.0   9.0   NaN\n",
      "4   5.0  10.0  15.0\n",
      "\n",
      "Median Imputation:\n",
      "    col1  col2  col3\n",
      "0   1.0   6.0  11.0\n",
      "1   2.0   NaN  12.0\n",
      "2   3.0   8.0  13.0\n",
      "3   4.0   9.0   NaN\n",
      "4   5.0  10.0  15.0\n",
      "\n",
      "Mode Imputation:\n",
      "    col1  col2  col3\n",
      "0   1.0   6.0  11.0\n",
      "1   2.0   NaN  12.0\n",
      "2   1.0   8.0  13.0\n",
      "3   4.0   9.0   NaN\n",
      "4   5.0  10.0  15.0\n",
      "\n",
      "Regression Imputation:\n",
      "    col1  col2  col3\n",
      "0   1.0   6.0  11.0\n",
      "1   2.0   NaN  12.0\n",
      "2   3.0   8.0  13.0\n",
      "3   4.0   9.0   NaN\n",
      "4   5.0  10.0  15.0\n",
      "\n",
      "Hot-Deck Imputation:\n",
      "    col1  col2  col3\n",
      "0   1.0   6.0  11.0\n",
      "1   2.0   NaN  12.0\n",
      "2   2.0   8.0  13.0\n",
      "3   4.0   9.0   NaN\n",
      "4   5.0  10.0  15.0\n",
      "\n",
      "K-Nearest Neighbors (KNN) imputation:\n",
      "    col1  col2  col3\n",
      "0   1.0   6.0  11.0\n",
      "1   2.0   7.0  12.0\n",
      "2   3.0   8.0  13.0\n",
      "3   4.0   9.0  14.0\n",
      "4   5.0  10.0  15.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# create a dataframe with missing values\n",
    "df = pd.DataFrame({\n",
    "    'col1': [1, 2, np.nan, 4, 5],\n",
    "    'col2': [6, np.nan, 8, 9, 10],\n",
    "    'col3': [11, 12, 13, np.nan, 15]\n",
    "})\n",
    "\n",
    "# display the dataframe\n",
    "print(\"Original data:\\n\", df)\n",
    "\n",
    "# Mean Imputation\n",
    "new_df = df.copy()\n",
    "mean_value = new_df['col1'].mean()\n",
    "new_df['col1'].fillna(value=mean_value, inplace=True)\n",
    "print(\"\\nMean Imputation:\\n\", new_df)\n",
    "\n",
    "# Median Imputation\n",
    "new_df = df.copy()\n",
    "median_value = new_df['col1'].median()\n",
    "new_df['col1'].fillna(value=median_value, inplace=True)\n",
    "print(\"\\nMedian Imputation:\\n\", new_df)\n",
    "\n",
    "# Mode Imputation\n",
    "new_df = df.copy()\n",
    "mode_value = new_df['col1'].mode()[0]\n",
    "new_df['col1'].fillna(value=mode_value, inplace=True)\n",
    "print(\"\\nMode Imputation:\\n\", new_df)\n",
    "\n",
    "# Regression Imputation\n",
    "new_df = df.copy()\n",
    "model = LinearRegression()\n",
    "x_train = new_df.dropna()[['col2', 'col3']]  # data points without missing values\n",
    "y_train = new_df.dropna()['col1']  # target variable without missing values\n",
    "model.fit(x_train, y_train)\n",
    "x_test = new_df[new_df['col1'].isna()][['col2', 'col3']]  # data points with missing values\n",
    "new_df.loc[df['col1'].isnull(), 'col1'] = model.predict(x_test)\n",
    "print(\"\\nRegression Imputation:\\n\", new_df)\n",
    "\n",
    "# Hot-Deck Imputation\n",
    "new_df = df.copy()\n",
    "missing_index = np.where(new_df['col1'].isnull())[0]\n",
    "for i in missing_index:\n",
    "    new_df.iloc[i, 0] = new_df.iloc[i-1, 0]  # fill missing values with value of the previous observation\n",
    "print(\"\\nHot-Deck Imputation:\\n\", new_df)\n",
    "\n",
    "# K-Nearest Neighbors (KNN) imputation\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "df_impute_knn = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "print(\"\\nK-Nearest Neighbors (KNN) imputation:\\n\", df_impute_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd42e7fe",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Prediction involves using a statistical or machine learning model to predict the missing values based on other variables in the dataset. This is similar to regression imputation but can be more powerful as it allows for more complex relationships between the variables. However, it requires a larger amount of data and can be computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3574c946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "    col1  col2  col3\n",
      "0   1.0   6.0  11.0\n",
      "1   2.0   NaN  12.0\n",
      "2   NaN   8.0  13.0\n",
      "3   4.0   9.0   NaN\n",
      "4   5.0  10.0  15.0\n",
      "\n",
      "Data after handling missing values:\n",
      "    col1  col2  col3\n",
      "0   1.0   6.0  11.0\n",
      "1   2.0   NaN  12.0\n",
      "2   3.0   8.0  13.0\n",
      "3   4.0   9.0   NaN\n",
      "4   5.0  10.0  15.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# create a dataframe with missing values\n",
    "df = pd.DataFrame({\n",
    "    'col1': [1, 2, np.nan, 4, 5],\n",
    "    'col2': [6, np.nan, 8, 9, 10],\n",
    "    'col3': [11, 12, 13, np.nan, 15]\n",
    "})\n",
    "print(\"Original data:\\n\", df)\n",
    "\n",
    "model = LinearRegression()\n",
    "x_train = df.dropna()[['col2', 'col3']]  # data points without missing values\n",
    "y_train = df.dropna()['col1']  # target variable without missing values\n",
    "model.fit(x_train, y_train)\n",
    "x_test = df[df['col1'].isnull()][['col2', 'col3']]  # data points with missing values\n",
    "df.loc[df['col1'].isnull(), 'col1'] = model.predict(x_test)  # fill missing values with predicted values\n",
    "print(\"\\nData after handling missing values:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c23b0f",
   "metadata": {},
   "source": [
    "## Interpolation\n",
    "\n",
    "Interpolation involves estimating the missing values based on the values of the neighboring points in the dataset. This is often used for time-series data where the missing values occur in a sequential order. There are several types of interpolation methods such as linear, cubic, and spline interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa890b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "    col1  col2  col3\n",
      "0   1.0   6.0  11.0\n",
      "1   2.0   NaN  12.0\n",
      "2   NaN   8.0  13.0\n",
      "3   4.0   9.0   NaN\n",
      "4   5.0  10.0  15.0\n",
      "\n",
      "Data after Interpolation:\n",
      "    col1  col2  col3\n",
      "0   1.0   6.0  11.0\n",
      "1   2.0   7.0  12.0\n",
      "2   3.0   8.0  13.0\n",
      "3   4.0   9.0  14.0\n",
      "4   5.0  10.0  15.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import interpolate\n",
    "\n",
    "# create a dataframe with missing values\n",
    "df = pd.DataFrame({\n",
    "    'col1': [1, 2, np.nan, 4, 5],\n",
    "    'col2': [6, np.nan, 8, 9, 10],\n",
    "    'col3': [11, 12, 13, np.nan, 15]\n",
    "})\n",
    "print(\"Original data:\\n\", df)\n",
    "\n",
    "df.interpolate(inplace=True)  # linear interpolation\n",
    "print(\"\\nData after Interpolation:\\n\", df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
