{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47071818",
   "metadata": {},
   "source": [
    "# Data Integration\n",
    "\n",
    "Data integration is the process of combining data from different sources into a single, unified view. It involves merging data from multiple sources and ensuring that the data is consistent and accurate.\n",
    "\n",
    "The need for data integration arises when organizations have data spread across multiple systems and applications, making it difficult to analyze and gain insights. For example, a company may have customer data stored in a CRM system, sales data stored in a separate database, and marketing data stored in yet another system. Integrating this data can provide a more complete picture of the business and help to identify trends and opportunities.\n",
    "\n",
    "There are several methods for data integration, including:\n",
    "\n",
    "- **Manual integration:** This involves manually combining data from different sources into a single dataset. It can be time-consuming and error-prone, but it may be necessary when dealing with small amounts of data or when the data sources are incompatible.\n",
    "- **Application programming interface (API) integration:** This involves using APIs to extract data from different systems and integrate it into a single dataset. It can be an efficient way to integrate data, but it requires technical expertise to set up and maintain. Python's `requests` library can be used for making API calls and fetching data from data sources that provide APIs. Other libraries like `urllib` and `http.client` can also be used for this purpose.\n",
    "- **ETL (extract, transform, load) integration:** This involves extracting data from different sources, transforming it to meet the needs of the target system, and loading it into a target database or data warehouse. ETL tools are commonly used to automate this process, making it more efficient and less error-prone. Python has several powerful ETL tools like `Apache Nifi`, `Apache Airflow`, and `Apache Beam`. These tools allow developers to extract data from various sources, perform transformations, and load it into a target database or data warehouse.\n",
    "- **Virtual integration:** This involves creating a virtual view of the data, where data from different sources appears as if it is stored in a single database. This approach can be useful when dealing with large amounts of data or when the data sources are incompatible. Virtual integration can be achieved using tools like `Apache Drill`, `Apache Calcite`, or `Apache Ignite`. These tools provide a virtual layer over multiple data sources, enabling users to access and analyze data from multiple sources as if they were a single source.\n",
    "\n",
    "Some of the commonly used data integration techniques include concatenation, merging, joining and stacking different datasets. Let's take a thorough look into each of those methods.\n",
    "\n",
    "## Concatenation\n",
    "\n",
    "Concatenation is the process of combining two or more dataframes by appending them along a particular axis. To concatenate two or more dataframes along rows or columns, you can use the `pd.concat()` function from the `pandas` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d04304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation by Row:\n",
      "    A  B\n",
      "0  1  4\n",
      "1  2  5\n",
      "2  3  6\n",
      "0  4  7\n",
      "1  5  8\n",
      "2  6  9\n",
      "\n",
      "Concatenation by Column:\n",
      "    A  B  A  B\n",
      "0  1  4  4  7\n",
      "1  2  5  5  8\n",
      "2  3  6  6  9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create two sample dataframes\n",
    "df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "df2 = pd.DataFrame({'A': [4, 5, 6], 'B': [7, 8, 9]})\n",
    "\n",
    "# concatenate dataframes along rows (axis=0)\n",
    "row_concatenated = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "# concatenate dataframes along columns (axis=1)\n",
    "col_concatenated = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "# print the concatenated dataframes\n",
    "print(\"Concatenation by Row:\\n\", row_concatenated)\n",
    "print(\"\\nConcatenation by Column:\\n\", col_concatenated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2889c51e",
   "metadata": {},
   "source": [
    "## Merging\n",
    "\n",
    "Merging is the process of combining two or more dataframes based on common columns. This technique is used when the datasets have some common columns. You can use the `pd.merge()` function from the `pandas` library to merge dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "820935f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value_x  value_y\n",
      "0   B        2        5\n",
      "1   D        4        6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create two sample dataframes\n",
    "df1 = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'value': [1, 2, 3, 4]})\n",
    "df2 = pd.DataFrame({'key': ['B', 'D', 'E', 'F'], 'value': [5, 6, 7, 8]})\n",
    "\n",
    "# merge dataframes on 'key' column\n",
    "merged = pd.merge(df1, df2, on='key')\n",
    "\n",
    "# print the merged dataframe\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea5233b",
   "metadata": {},
   "source": [
    "## Joining\n",
    "\n",
    "Joining is similar to merging, but is specifically used to combine dataframes based on their indexes. You can use the `pd.DataFrame.join()` method to join dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce3bdf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C   D\n",
      "X  1  4  7  10\n",
      "Y  2  5  8  11\n",
      "Z  3  6  9  12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create two sample dataframes\n",
    "df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]}, index=['X', 'Y', 'Z'])\n",
    "df2 = pd.DataFrame({'C': [7, 8, 9], 'D': [10, 11, 12]}, index=['X', 'Y', 'Z'])\n",
    "\n",
    "# join dataframes\n",
    "joined = df1.join(df2)\n",
    "\n",
    "# print the joined dataframe\n",
    "print(joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83afc145",
   "metadata": {},
   "source": [
    "## Stacking\n",
    "\n",
    "Stacking is the process of vertically combining datasets with the same columns. The datasets are aligned by their column names and then stacked on top of each other. You can use the `pd.stack()` function to stack a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26063352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X  A    1\n",
      "   B    4\n",
      "Y  A    2\n",
      "   B    5\n",
      "Z  A    3\n",
      "   B    6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a dataframe to be stacked\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]}, index=['X', 'Y', 'Z'])\n",
    "\n",
    "# stack the dataframe\n",
    "result = df.stack()\n",
    "\n",
    "# print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc576b3",
   "metadata": {},
   "source": [
    "You can use the `pd.concat()` function with the `keys` parameter to stack multiple dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eedd834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       A  B\n",
      "df1 0  1  4\n",
      "    1  2  5\n",
      "    2  3  6\n",
      "df2 0  4  7\n",
      "    1  5  8\n",
      "    2  6  9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create two sample dataframes\n",
    "df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "df2 = pd.DataFrame({'A': [4, 5, 6], 'B': [7, 8, 9]})\n",
    "\n",
    "# stack dataframes\n",
    "stacked = pd.concat([df1, df2], keys=['df1', 'df2'])\n",
    "\n",
    "# print the stacked dataframe\n",
    "print(stacked)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
