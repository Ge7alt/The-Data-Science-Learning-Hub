{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3ab7c82",
   "metadata": {},
   "source": [
    "# Data discretization\n",
    "\n",
    "Data discretization is the process of converting continuous numerical data into categorical or discrete data. It is a data preprocessing technique that is used to reduce data complexity, remove noise, and improve accuracy. It is commonly used in machine learning, data mining, and other data analysis applications.\n",
    "\n",
    "There are two main types of data discretization:\n",
    "\n",
    "## Equal width binning\n",
    "\n",
    "Equal width binning is a data discretization method that divides a continuous variable into equal-width intervals, or bins. The width of each bin is determined by dividing the range of the variable by the number of desired bins.\n",
    "\n",
    "For example, suppose we have a continuous variable with a range of 0 to 100 and we want to divide it into 5 bins. Each bin would have a width of (100-0)/5 = 20. The first bin would then include values from 0 to 20, the second bin would include values from 20 to 40, and so on.\n",
    "\n",
    "Equal width binning is a simple and easy-to-understand method of discretization, but it may not always be the most effective. In cases where the distribution of the data is not uniform, some bins may have very few observations, while others may have a large number. This can result in loss of information and reduced accuracy in analysis. Other methods of discretization, such as equal frequency binning and entropy-based binning, may be more appropriate in such cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610e35e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A           bin\n",
      "0  60  (59.4, 79.2]\n",
      "1  64  (59.4, 79.2]\n",
      "2  54  (39.6, 59.4]\n",
      "3  81  (79.2, 99.0]\n",
      "4  59  (39.6, 59.4]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample dataset\n",
    "df = pd.DataFrame({'A': np.random.randint(0, 100, size=100)})\n",
    "\n",
    "# Define the number of bins and bin width\n",
    "num_bins = 5\n",
    "bin_width = (df['A'].max() - df['A'].min()) / num_bins\n",
    "\n",
    "# Create the bins\n",
    "bins = []\n",
    "for i in range(num_bins):\n",
    "    bins.append(df['A'].min() + i * bin_width)\n",
    "bins.append(df['A'].max())\n",
    "\n",
    "# Assign each value to a bin\n",
    "df['bin'] = pd.cut(df['A'], bins=bins)\n",
    "\n",
    "# Print the resulting dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0783440e",
   "metadata": {},
   "source": [
    "This code generates a random dataset with a single column `'A'`. It then calculates the bin width based on the range of values in `'A'` and the desired number of bins. It creates a list of bin edges, and uses the `cut` function from `pandas` to assign each value in `'A'` to a bin. The resulting dataframe includes a new column `'bin'` with the assigned bin for each value.\n",
    "\n",
    "## Equal frequency binning\n",
    "\n",
    "Equal frequency binning, also known as quantile-based binning or histogram-based binning, is a method of discretization that divides the data into equal frequency intervals. The goal of this method is to ensure that each interval contains the same number of observations. This can be particularly useful when the data distribution is skewed, and we want to ensure that each bin contains a representative sample of the data.\n",
    "\n",
    "The steps involved in equal frequency binning are as follows:\n",
    "\n",
    "- Sort the data in ascending order.\n",
    "- Divide the data into n equal parts, where n is the desired number of bins.\n",
    "- Assign each observation to the corresponding bin.\n",
    "\n",
    "In Python, we can perform equal frequency binning using the `qcut()` function from the `pandas` library. This function divides the data into quantiles, or equal frequency intervals, and assigns a label to each observation based on the bin it falls into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f8252bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A    B  A_binned  B_binned\n",
      "0   1   10         0         0\n",
      "1   2   20         0         0\n",
      "2   3   30         0         0\n",
      "3   4   40         1         1\n",
      "4   5   50         1         1\n",
      "5   6   60         2         2\n",
      "6   7   70         2         2\n",
      "7   8   80         3         3\n",
      "8   9   90         3         3\n",
      "9  10  100         3         3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a dataset\n",
    "data = pd.DataFrame({'A': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                     'B': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]})\n",
    "\n",
    "# divide the data into 4 equal frequency bins\n",
    "data['A_binned'] = pd.qcut(data['A'], q=4, labels=False)\n",
    "data['B_binned'] = pd.qcut(data['B'], q=4, labels=False)\n",
    "\n",
    "# print the binned data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8827f50",
   "metadata": {},
   "source": [
    "## Entropy-based Discretization\n",
    "\n",
    "Entropy-based discretization is a method used to discretize continuous data by dividing it into intervals that maximize the information gain or minimize the entropy of the resulting classes. The goal of this method is to find the optimal threshold values for dividing continuous data into discrete intervals that maximize the information gain or minimize the entropy.\n",
    "\n",
    "The entropy of a class is a measure of the degree of impurity in the class. In other words, it measures how much uncertainty there is in predicting the class of a data point. The entropy is calculated as:\n",
    "\n",
    "$Entropy = -\\sum_{i=1}^{k} p_i\\log_2(p_i)$\n",
    "\n",
    "where $n$ is the number of classes and $p_i$ is the proportion of data points that belong to class $i$.\n",
    "\n",
    "The information gain is the difference between the entropy of the original data and the weighted average of the entropies of the resulting classes after the data has been split based on a particular threshold. The information gain is used as a criterion to evaluate the quality of a split.\n",
    "\n",
    "There are several algorithms for entropy-based discretization, such as Fayyad and Irani's algorithm and ChiMerge algorithm. These algorithms differ in the way they determine the optimal threshold values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bd76b49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A    B  B_discretized\n",
      "0   1   20              0\n",
      "1   2   30              0\n",
      "2   3   40              0\n",
      "3   4   50              1\n",
      "4   5   60              1\n",
      "5   6   70              1\n",
      "6   7   80              1\n",
      "7   8   90              1\n",
      "8   9  100              1\n",
      "9  10  200              1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def entropy_based_discretization(series, bins):\n",
    "    # Calculate entropy for each possible split\n",
    "    entropy = []\n",
    "    for i in range(1, len(bins)):\n",
    "        split = np.where(series < bins[i], 0, 1)\n",
    "        p0 = np.count_nonzero(split == 0) / len(split)\n",
    "        p1 = 1 - p0\n",
    "        e0 = 0 if p0 == 0 else -p0 * np.log2(p0)\n",
    "        e1 = 0 if p1 == 0 else -p1 * np.log2(p1)\n",
    "        entropy.append(e0 + e1)\n",
    "\n",
    "    # Find the split with maximum entropy\n",
    "    idx = np.argmax(entropy)\n",
    "    split = np.where(series < bins[idx + 1], 0, 1)\n",
    "\n",
    "    # Return the discretized series\n",
    "    return pd.Series(split, index=series.index)\n",
    "\n",
    "\n",
    "# Create a dummy dataset\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'B': [20, 30, 40, 50, 60, 70, 80, 90, 100, 200]\n",
    "})\n",
    "\n",
    "# Discretize column 'B' using entropy-based method\n",
    "bins = [0, 50, 100, 200]\n",
    "df['B_discretized'] = entropy_based_discretization(df['B'], bins)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdaec97",
   "metadata": {},
   "source": [
    "In this example, we are creating a dummy dataset and discretizing the `'B'` column using the entropy-based method by calling the `entropy_based_discretization()` function. The resulting discretized column is added to the original dataframe as `'B_discretized'`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
