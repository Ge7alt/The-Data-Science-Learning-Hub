{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a110e5c2",
   "metadata": {},
   "source": [
    "# Data Pipeline Design and Implementation\n",
    "\n",
    "## Data Extraction\n",
    "\n",
    "Data extraction is the process of collecting data from various sources such as databases, APIs, or files. In Python, you can use libraries like `requests` or `pandas` to extract data from various sources. Here's an example of how to extract data from a REST API using `requests`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b5d075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define API endpoint\n",
    "endpoint = 'https://api.example.com/data'\n",
    "\n",
    "# Send GET request to API endpoint\n",
    "response = requests.get(endpoint)\n",
    "\n",
    "# Extract data from response\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d5059c",
   "metadata": {},
   "source": [
    "## Data Transformation\n",
    "\n",
    "Data transformation is the process of converting data from one format to another or applying operations to it. In Python, you can use libraries like `pandas` or `numpy` to transform data. Here's an example of how to transform data in a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3bb648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from CSV file into DataFrame\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Transform data\n",
    "data['salary'] = data['salary'] * 1.1\n",
    "\n",
    "# Write transformed data to CSV file\n",
    "data.to_csv('transformed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8fdade",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Data loading is the process of storing data in a database or a file. In Python, you can use libraries like `pandas` or `sqlite3` to load data. Here's an example of how to load data into a SQLite database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749167f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Read data from CSV file into DataFrame\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Create database connection\n",
    "conn = sqlite3.connect('data.db')\n",
    "\n",
    "# Load data into database\n",
    "data.to_sql('employees', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9848595",
   "metadata": {},
   "source": [
    "## Data Pipeline Design\n",
    "\n",
    "Data pipeline design involves planning the flow of data from source to destination and designing the steps involved in the pipeline. In Python, you can use tools like `Apache Airflow` or `Luigi` to design data pipelines. Here's an example of how to define a simple data pipeline in `Luigi`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab62611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import luigi\n",
    "\n",
    "class ExtractData(luigi.Task):\n",
    "    def output(self):\n",
    "        return luigi.LocalTarget('data.json')\n",
    "\n",
    "    def run(self):\n",
    "        # Extract data from API endpoint\n",
    "        data = ...\n",
    "\n",
    "        # Write data to file\n",
    "        with self.output().open('w') as f:\n",
    "            f.write(data)\n",
    "\n",
    "class TransformData(luigi.Task):\n",
    "    def requires(self):\n",
    "        return ExtractData()\n",
    "\n",
    "    def output(self):\n",
    "        return luigi.LocalTarget('transformed_data.csv')\n",
    "\n",
    "    def run(self):\n",
    "        # Read data from file into DataFrame\n",
    "        data = pd.read_json(self.input().path)\n",
    "\n",
    "        # Transform data\n",
    "        data['salary'] = data['salary'] * 1.1\n",
    "\n",
    "        # Write transformed data to CSV file\n",
    "        data.to_csv(self.output().path, index=False)\n",
    "\n",
    "class LoadData(luigi.Task):\n",
    "    def requires(self):\n",
    "        return TransformData()\n",
    "\n",
    "    def run(self):\n",
    "        # Read data from file into DataFrame\n",
    "        data = pd.read_csv(self.input().path)\n",
    "\n",
    "        # Load data into database\n",
    "        data.to_sql('employees', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c47649c",
   "metadata": {},
   "source": [
    "## Data Pipeline Implementation\n",
    "\n",
    "Data pipeline implementation involves executing the steps defined in the pipeline and monitoring the pipeline for errors or failures. In Python, you can use tools like `Luigi` or `Apache Airflow` to implement and execute data pipelines. Here's an example of how to execute the data pipeline defined in the previous example using `Luigi`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47cfc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
