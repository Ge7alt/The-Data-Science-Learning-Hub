{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Logistic regression is a popular statistical model used for binary classification problems. It aims to estimate the probability that an instance belongs to a particular class. The model assumes a linear relationship between the predictors and the log-odds of the event occurring. In this response, I'll explain the geometrical intuition behind logistic regression and provide the necessary formulas.\n",
    "\n",
    "- **Assumption:** Classes are almost perfectly linerarly separable.\n",
    "\n",
    "## Geometrical Intuition\n",
    "\n",
    "In logistic regression, we can interpret the output as the probability of an instance belonging to a particular class. The decision boundary that separates the two classes is a hyperplane in the feature space. Since logistic regression is a binary classifier, this hyperplane divides the feature space into two regionsâ€”one for each class.\n",
    "\n",
    "The decision boundary is determined by the weights (coefficients) assigned to the predictors. These weights control the orientation and tilt of the hyperplane. By adjusting the weights, logistic regression finds the best-fitting decision boundary that maximizes the likelihood of the observed data.\n",
    "\n",
    "In logistic regression, we take $y=+1$ for positive points and $y=-1$ for negative points. Also $y=mx$ in higher dimension becomes $w^Tx+b=0$, where $w$ is normal drawn from the plane to the current point $x$ and $b$ is the intercept.\n",
    "\n",
    "When plane passes through origin $b=0$ so the equatio becomes $w^Tx=0$\n",
    "\n",
    "![Logistic Regression](./../../assets/logistic.jpg)\n",
    "\n",
    "From Figure,\n",
    "$distance(S_i) = \\frac{w^Tx}{||w||}$\n",
    "\n",
    "If $||w||$ is a unit vector i.e. $||w||=1$\n",
    "\n",
    "$S_i = w^Tx_i > 0$\n",
    "\n",
    "$S_j = w^Tx_j < 0$\n",
    "\n",
    "$y_i * w^Tx_i > 0$ means $w$ is correctly classifying the point while $y_i * w^Tx_i < 0$ means $w$ is misclassifying the point\n",
    "\n",
    "- **Case I:** $y_i = +ve$ and $w^Tx_i = +ve$ then $y_i * w^Tx_i > 0$ i.e. $x_i$ is correctly classified\n",
    "- **Case II:** $y_i = -ve$ and $w^Tx_i = -ve$ then $y_i * w^Tx_i > 0$ i.e. $x_i$ is correctly classified\n",
    "- **Case III:** $y_i = +ve$ and $w^Tx_i = -ve$ then $y_i * w^Tx_i < 0$ i.e. $x_i$ is incorrectly classified\n",
    "- **Case IV:** $y_i = -ve$ and $w^Tx_i = +ve$ then $y_i * w^Tx_i < 0$ i.e. $x_i$ is incorrectly classified\n",
    "\n",
    "So the value of $w$ is chosen shuch that it gives the maximum number of points that are correctly classified points i.e. maximum value of $\\sum{y_i*w^Tx_i}$. So we need to optimize the value of $w$ and the optimal value of the normal $w$ is given by;\n",
    "\n",
    "\\begin{equation}\n",
    "w^* = argmax_w (\\sum{y_i*w^Tx_i})\n",
    "\\end{equation}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
